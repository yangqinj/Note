{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980a2320",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#动态图和静态图\" data-toc-modified-id=\"动态图和静态图-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>动态图和静态图</a></span></li><li><span><a href=\"#JIT和核心概念\" data-toc-modified-id=\"JIT和核心概念-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>JIT和核心概念</a></span></li><li><span><a href=\"#tracing-vs-script\" data-toc-modified-id=\"tracing-vs-script-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>tracing vs script</a></span><ul class=\"toc-item\"><li><span><a href=\"#torch.jit.trace\" data-toc-modified-id=\"torch.jit.trace-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>torch.jit.trace</a></span></li><li><span><a href=\"#torch.jit.script\" data-toc-modified-id=\"torch.jit.script-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>torch.jit.script</a></span></li></ul></li><li><span><a href=\"#参考\" data-toc-modified-id=\"参考-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>参考</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b72d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e839dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833dc8a1",
   "metadata": {},
   "source": [
    "pytorch为了提升模型的推理速度以及兼容torch模型在不同平台上运行，提出了pytorch模型的中间表示——TorchScript。当我们在将pytorch模型转换成onnx模型的过程时，pytorch模型其实首先被转换为了torch.jit.ScriptModule，在将TorchScript算子转换为onnx算子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31aad7",
   "metadata": {},
   "source": [
    "## 动态图和静态图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376b844",
   "metadata": {},
   "source": [
    "众所周知，我们在使用pytorch训练模型时是可以通过print或者log方式输出中间结果的，但是在TensorFlow中却做不到。这是因为pytorch是实时执行的，构造出来的模型使用的是动态图方式，而TensorFlow则是在一开始就把整个图构建好再运行，提供的是静态图方式。\n",
    "\n",
    "由于动态图实时构建的特点，她并不适用于推理，但是静态图却适合，并且静态图可以通过多种方式进行优化从而提升推理性能。因此，pytorch为了提高推理速度提出了中间表示（Intermediate Representation, IR）TorchScript，它通过将动态图转换为静态图的方式达到以下几种优势：\n",
    "+ TorchScript的代码可以通过它特有的解释器(PyTorch JIT Compiler)来加载和运行，这个解释器没有python中的GIL锁，从而可以支持多线程和多并发\n",
    "+ 由于是中间表示，所以可以在其他非python环境上加载，如C++，或者其他非pytorch框架上运行\n",
    "+ 原始静态图可以进一步优化从而提升推理速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0540d9",
   "metadata": {},
   "source": [
    "## JIT和核心概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00557afb",
   "metadata": {},
   "source": [
    "JIT是一个专门为TorchScript服务的解释器，它可以优化在python层定义的nn.Module模型，将其转换为TorchScript的模型并且运行。TorchScript既然是一种中间表示，肯定是有自己特有的表达方式的，类似于onnx中的protobuf，这个部分在后面可能会讲解到。但是，TorchScript在JIT中的核心概念其实是与python中的对应：\n",
    "+ Module: 对应nn.Module，代表一个模块或者一个模型\n",
    "+ Parameter: 对应nn.Parameters，代表模型参数（权重、偏置、embedding等）\n",
    "+ Buffer：对应Tensor，用于模型训练过程中的数据记录，但是不参与梯度传播\n",
    "+ Attribute：对应模型初始化时的配置，不会被保存到模型文件中\n",
    "+ Method：模型的相关函数，比如forward\n",
    "+ FunctionSchema：用于描述Method的输入和输出的类型、大小等属性\n",
    "+ Graph：是Method中的代码（我觉得之所以把代码称为Graph，是因为这些代码使用的算子最终会成为静态图的节点并构成一个子图）。一个Graph由Block、Node和Value组成：\n",
    "  - Block: \n",
    "  - Node:\n",
    "  - Value: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb52e3",
   "metadata": {},
   "source": [
    "## tracing vs script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ec433cf",
   "metadata": {},
   "source": [
    "TorchScript提供两种方式将torch.nn.Module转换为ScriptModule：torch.jit.trace和torch.jit.script：\n",
    "+ trace方式是根据输入将整个模型实际运行一遍，代码从python层解析到C++层中的具体算子，因此不支持控制流（if/while等语句）\n",
    "+ script方式是在python层根据代码逻辑进行转换，支持控制流，但是却因为python语句的灵活性存在转换失败的可能\n",
    "+ 在torch 2.x版本中逐渐转换为将TorchDynamo作为转换静态图的主要方式，即从模型的二进制文件中读取模型结构\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f95419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if torch.sum(x) > 10:\n",
    "            return x\n",
    "        else:\n",
    "            return x + 10\n",
    "\n",
    "torch_model = CondModel()\n",
    "input_x = torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be9ba9",
   "metadata": {},
   "source": [
    "### torch.jit.trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "909cd62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangqj/miniconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trace_model = torch.jit.trace(torch_model, input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da33cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.___torch_mangle_3.CondModel,\n",
       "      %x : Float(2, 3, strides=[3, 1], requires_grad=0, device=cpu)):\n",
       "  %8 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]() # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/3381973082.py:9:0\n",
       "  %9 : int = prim::Constant[value=1]() # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/3381973082.py:9:0\n",
       "  %10 : Float(2, 3, strides=[3, 1], requires_grad=0, device=cpu) = aten::add(%x, %8, %9) # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/3381973082.py:9:0\n",
       "  return (%10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_model.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f185f4",
   "metadata": {},
   "source": [
    "使用model.graph可以查到生成的静态图，但这是底层的表示方法难以看懂，可以使用model.code方式查看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "052663ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  return torch.add(x, CONSTANTS.c0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trace_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb32702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.CondModel,\n",
       "      %x : Float(2, 3, strides=[3, 1], requires_grad=0, device=cpu)):\n",
       "  %8 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]() # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/4284957722.py:9:0\n",
       "  %9 : int = prim::Constant[value=1]() # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/4284957722.py:9:0\n",
       "  %10 : Float(2, 3, strides=[3, 1], requires_grad=0, device=cpu) = aten::add(%x, %8, %9) # /var/folders/3p/mvrxlkq16dlfhgxbl9f31bvh0000gn/T/ipykernel_2299/4284957722.py:9:0\n",
       "  return (%10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722228d1",
   "metadata": {},
   "source": [
    "可以观察到生成的ScriptModel中缺少了条件判断语句，直接返回输入和10的结果。可以比较一下两个模型的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd08d0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.3035, 10.4609, 10.7085],\n",
       "         [10.6423, 10.9892, 10.7417]]),\n",
       " tensor([[10.3035, 10.4609, 10.7085],\n",
       "         [10.6423, 10.9892, 10.7417]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model(input_x), trace_model(input_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68672a7",
   "metadata": {},
   "source": [
    "结果是一致的。但是当我们更换一个输入时结果却不相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b416d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5.],\n",
       "         [5., 5., 5.]]),\n",
       " tensor([[15., 15., 15.],\n",
       "         [15., 15., 15.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_y = torch.ones(2, 3) * 5\n",
    "torch_model(input_y), trace_model(input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b2790ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit._trace.TopLevelTracedModule"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_model.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff5ca0",
   "metadata": {},
   "source": [
    "### torch.jit.script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d366088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_model = torch.jit.script(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "478517f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 10)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.add(x, 10)\n",
      "  return _0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(script_model.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece9599",
   "metadata": {},
   "source": [
    "可以看到script方式保留了条件判断语句，所以得到的结果会与torch_model完全一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e298e83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.3035, 10.4609, 10.7085],\n",
       "         [10.6423, 10.9892, 10.7417]]),\n",
       " tensor([[10.3035, 10.4609, 10.7085],\n",
       "         [10.6423, 10.9892, 10.7417]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model(input_x), script_model(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21aa6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5.],\n",
       "         [5., 5., 5.]]),\n",
       " tensor([[5., 5., 5.],\n",
       "         [5., 5., 5.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model(input_y), script_model(input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35b61f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit._script.RecursiveScriptModule"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_model.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf2545",
   "metadata": {},
   "source": [
    "关于这两种方式的底层源代码调用逻辑可以参考 `SourceCode/Torch/3_torch_script.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112375dc",
   "metadata": {},
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97535617",
   "metadata": {},
   "source": [
    "+ TorchScript介绍：https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\n",
    "+ C++运行ScriptModule： https://pytorch.org/tutorials/advanced/cpp_export.html\n",
    "+ pytorch转换为onnx: https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
    "+ openmmlab的TorchScript系列文章：https://zhuanlan.zhihu.com/p/486914187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf6596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "510px",
    "left": "985.456px",
    "top": "232px",
    "width": "246.364px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
