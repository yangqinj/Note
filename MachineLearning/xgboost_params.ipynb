{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#通用参数\" data-toc-modified-id=\"通用参数-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>通用参数</a></span></li><li><span><a href=\"#树booster的参数\" data-toc-modified-id=\"树booster的参数-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>树booster的参数</a></span></li><li><span><a href=\"#任务参数\" data-toc-modified-id=\"任务参数-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>任务参数</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST有多种语言的实验版本，C++、pyhton、R等，我选择了pyhton语言。pyhton语言的接口，还分为原生的XGBOOST（即官网提供的whl包）以及scikit-learn封装的XGBOOST接口，这里我选择了官网的接口。使用的版本为0.9.0\n",
    "\n",
    "XGBOOST中的参数共分为三种：通用参数(general parameters)、提升参数(booster parameters)和任务参数(task parameters)。\n",
    "\n",
    "参考资料: https://xgboost.readthedocs.io/en/release_0.90/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost                            0.90     \r\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通用参数\n",
    "\n",
    "+ booster [default= gbtree ]\n",
    "表示选择哪一种提升器，可以是gbtree, gblinear和dart。 dart在gbtree的基础上使用概率dropout技术防止过拟合。\n",
    "\n",
    "+ verbosity [default=1]\n",
    "日志的等级，0(silent), 1(warning), 2(info), 3(debug)\n",
    "\n",
    "+ nthreads [default=默认最大线程数]\n",
    "+ num_pbuffer [不需要用户手动设置]\n",
    "预测缓冲区的大小，通常设置为训练样本的个数，buffer用来存储最后一步的预测结果。\n",
    "+ num_feature [不需要用户手动设置]\n",
    "在提升阶段使用的特征维度，设置为特征的最大维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 树booster的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ eta [default=0.3, alias: learning_rate]\n",
    "缩小因子，用于防止过拟合。每次构建完一棵树的时候，叶子节点的w值需要乘以这个缩小因子。在0到1的范围之间。\n",
    "\n",
    "\n",
    "+ gamma [default=0, alias: min_split_loss]\n",
    "当节点的预测的loss值低于这个值的时候，不再继续划分节点。\n",
    "\n",
    "\n",
    "+ max_depth [default=6]\n",
    "\n",
    "\n",
    "+ min_child_weight [default=1]\n",
    "每个子节点的样本权重之和的最小值，每个样本的权重就是它对应的二阶导数，所以这个参数就是对应了H。当节点的H值小于这个参数时，停止继续划分。\n",
    "\n",
    "\n",
    "+ max_delta_step [default=0]\n",
    "没整明白。通常不需要设置，只有在类别极度不平衡且使用lr算法时起作用。\n",
    "\n",
    "\n",
    "+ subsample [default=1]\n",
    "每次构建树的时候，只采样部分样本用于训练。范围在0到1之间。\n",
    "\n",
    "\n",
    "+ colsample_bytree [default=1]\n",
    "每次构建树的时候，只选择部分的属性用于训练。\n",
    "\n",
    "\n",
    "+ colsample_bylevel [default=1]\n",
    "每当树到达新的深度的时候，采样部分属性用于训练。\n",
    "\n",
    "\n",
    "+ colsample_bynode [default=1]\n",
    "每次划分节点的时候，只采样部分属性用于训练。\n",
    "\n",
    "\n",
    "+ lambda [default=1, alias: reg_lambda]\n",
    "L2正则化项的参数。\n",
    "\n",
    "\n",
    "+ alpha [default=0, alias: reg_alpha]\n",
    "L1正则化项的参数。\n",
    "\n",
    "\n",
    "+ tree_method string [default= auto]\n",
    "选择最佳属性划分点的方法。\n",
    " - auto: 根据数据集的大小使用启发式的方法决定划分方法。对于中小型数据集，使用exact；对非常大的数据集使用approx.\n",
    " - exact: 遍历所有可能的划分点。\n",
    " - approx: 根据属性值的特点来选取若干个候选划分点，从中找到最佳分割点。\n",
    " - hist: 根据导数直方图的分布来选择候选节点。（不是太懂）\n",
    " - gpu_exact\n",
    " - gpu_hist\n",
    "\n",
    "+ sketch_eps [default=0.03]\n",
    "\n",
    "\n",
    "+ scale_pos_weight [default=1]\n",
    "控制正负样本的权重，通常用在正负样本不平衡的时候。\n",
    "\n",
    "\n",
    "+ updater [default= grow_colmaker,prune]\n",
    "提供了一种模块的方法来设置树的创建和训练过程。\n",
    "+ refresh_leaf [default=1]\n",
    "+ process_type [default= default]\n",
    "+ grow_policy [default= depthwise]\n",
    "+ max_leaves [default=0]\n",
    "+ max_bin, [default=256]\n",
    "+ predictor, [default=``cpu_predictor``]\n",
    "\n",
    "\n",
    "+ num_parallel_tree, [default=1]\n",
    "并行树的个数，用于RF中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务参数\n",
    "+ objective [default=reg:squarederror]\n",
    "目标函数\n",
    "\n",
    " - reg:squarederror: regression with squared loss\n",
    " - reg:logistic: logistic regression\n",
    " - binary:logistic: logistic regression for binary classification, output probability\n",
    " - binary:logitraw: logistic regression for binary classification, output score before logistic transformation\n",
    " - binary:hinge: hinge loss for binary classification. This makes predictions of 0 or 1, rather than producing probabilities.\n",
    " - count:poisson –poisson regression for count data, output mean of poisson distribution\n",
    " - max_delta_step is set to 0.7 by default in poisson regression (used to safeguard optimization)\n",
    " - survival:cox: Cox regression for right censored survival time data (negative values are considered right censored). Note that predictions are returned on the hazard ratio scale (i.e., as HR = exp(marginal_prediction) in the proportional hazard function h(t) = h0(t) * HR).\n",
    " - multi:softmax: set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)\n",
    " - multi:softprob: same as softmax, but output a vector of ndata * nclass, which can be further reshaped to ndata * nclass matrix. The result contains predicted probability of each data point belonging to each class.\n",
    " - rank:pairwise: Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n",
    " - rank:ndcg: Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n",
    " - rank:map: Use LambdaMART to perform list-wise ranking where Mean Average Precision (MAP) is maximized\n",
    " - reg:gamma: gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be gamma-distributed.\n",
    " - reg:tweedie: Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be Tweedie-distributed.\n",
    "\n",
    "+ base_score [default=0.5]\n",
    "初始时候的score值。\n",
    "\n",
    "\n",
    "+ eval_metric\n",
    "验证集使用的评估准则，默认根据目标函数决定（回归用rmse，分类用错误率，排序用平均精度），也可以手动设置。\n",
    " - rmse: root mean square error\n",
    " - mae: mean absolute error\n",
    " - logloss: negative log-likelihood\n",
    " - error: Binary classification error rate. It is calculated as #(wrong cases)/#(all cases). For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.\n",
    " - error@t: a different than 0.5 binary classification threshold value could be specified by providing a numerical value through ‘t’.\n",
    " - merror: Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases).\n",
    " - mlogloss: Multiclass logloss.\n",
    " - auc: Area under the curve\n",
    " - aucpr: Area under the PR curve\n",
    " - ndcg: Normalized Discounted Cumulative Gain\n",
    " - map: Mean Average Precision\n",
    " - ndcg@n, map@n: ‘n’ can be assigned as an integer to cut off the top positions in the lists for evaluation.\n",
    " - ndcg-, map-, ndcg@n-, map@n-: In XGBoost, NDCG and MAP will evaluate the score of a list without any positive samples as 1. By adding “-” in the evaluation metric XGBoost will evaluate these score as 0 to be consistent under some conditions.\n",
    " - poisson-nloglik: negative log-likelihood for Poisson regression\n",
    " - gamma-nloglik: negative log-likelihood for gamma regression\n",
    " - cox-nloglik: negative partial log-likelihood for Cox proportional hazards regression\n",
    " - gamma-deviance: residual deviance for gamma regression\n",
    " - tweedie-nloglik: negative log-likelihood for Tweedie regression (at a specified value of the tweedie_variance_power parameter)\n",
    " \n",
    "+ seed [default=0]\n",
    "随机种子值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
